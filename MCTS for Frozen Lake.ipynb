{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.envs.registration import register  # https://github.com/openai/gym/blob/master/gym/envs/registration.py\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "MY_ENV_NAME='FrozenLakeNonskid4x4-v0'\n",
    "\n",
    "# 0 = left; 1 = down; 2 = right;  3 = up\n",
    "# reward of 1 if success, no reward otherwise\n",
    "# done = True even if not success due to timestep limit\n",
    "\n",
    "register(\n",
    "    id=MY_ENV_NAME,\n",
    "    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "    kwargs={'map_name': '8x8', 'is_slippery': False},\n",
    "    reward_threshold=0.78)\n",
    "\n",
    "env = gym.make(MY_ENV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \"\"\"\n",
    "    each state will be represented as a State object. we do this \n",
    "    because we want to track (a) total rewards and (b) play count.\n",
    "    \n",
    "    we need to track rewards and play count in order to calculate\n",
    "    UCB score; we want to calculate UCB score in order to select \n",
    "    the most promising action.\n",
    "    \"\"\"\n",
    "    def __init__(self, state):\n",
    "        self.state = state\n",
    "        self.q = 0  # win count\n",
    "        self.n = 0  # play count\n",
    "\n",
    "\n",
    "def _find_valid_action_state_pairs(s1, env):\n",
    "    \"\"\"return a list of valid action/s2 pairs for a given s1.\n",
    "    \"\"\"\n",
    "    valid_actions = []\n",
    "    \n",
    "    # explore all four possible actions\n",
    "    for a in range(3):  \n",
    "        s2, _, _, _ = env.step(a)  # what would s2 look like if we took action a\n",
    "        \n",
    "        # scenario 1: action does not lead to a new state, so ignore\n",
    "        if s2 == s1:\n",
    "            pass\n",
    "        \n",
    "        # scenario 2: action leads to a new state so we will keep it\n",
    "        else:\n",
    "            valid_actions.append((a, s2))\n",
    "        \n",
    "        # return env to original state\n",
    "        env.s = s1  \n",
    "    return valid_actions\n",
    "        \n",
    "\n",
    "def _find_valid_actions(s, env):\n",
    "    \"\"\"return a list of valid actions for state s.\n",
    "    \"\"\"\n",
    "    valid_actions = []\n",
    "    \n",
    "    # explore all four actions and see if they are valid\n",
    "    for a in range(3):  \n",
    "        s2, _, _, _ = env.step(a)  # what would s2 look like if we took action a\n",
    "        \n",
    "        # scenario 1: action does not lead to a new state, so ignore\n",
    "        if s2 == s:\n",
    "            pass\n",
    "        \n",
    "        # scenario 2: action leads to a new state so we will keep it\n",
    "        else:\n",
    "            valid_actions.append(a)\n",
    "        \n",
    "        # return env to original state\n",
    "        env.s = s\n",
    "    return valid_actions\n",
    "\n",
    "    \n",
    "def select_action_from_root(root, memory, env):\n",
    "    \"\"\"return an action from root. \n",
    "    \n",
    "    if root is unexpanded then return actions that lead to unexplored \n",
    "    states. if root is expanded (all possible s2 from root s1 have \n",
    "    been explored) then return action that leads to s2 with highest \n",
    "    UCB score.\n",
    "    \"\"\"\n",
    "    # step 1: find all actions that would lead to a valid state\n",
    "    action_states = _find_valid_action_state_pairs(root, env)\n",
    "    \n",
    "    # step 2a: if we havent seen that s2 before, then go with it\n",
    "    for ap in action_states:\n",
    "        a = ap[0]\n",
    "        s2 = ap[1]\n",
    "        if s2 in memory.keys():\n",
    "            pass\n",
    "        else:\n",
    "            return a  # this action leads to a state that we havent seen before\n",
    "        \n",
    "    # step 2b: if we've visited all possible s2 from root, return action that would lead to s2 with the highest UCB\n",
    "    action = action_states[0][0]\n",
    "    max_ucb = 0\n",
    "    for ap in action_states:\n",
    "        s1 = memory[root]\n",
    "        s2 = memory[ap[1]]\n",
    "        score = calculate_ucb(s1, s2)\n",
    "        if score > max_ucb:\n",
    "            action = ap[0]\n",
    "            max_ucb = score  # new score to beat\n",
    "    return action\n",
    "    \n",
    "def calculate_ucb(s1, s2):\n",
    "    \"\"\"compute ucb score between s1 and s2.\n",
    "    \"\"\"\n",
    "    c_param = .14\n",
    "    \n",
    "    # hack in case s2 is a pit\n",
    "    if s2.n == 0:\n",
    "        s2.n = 1\n",
    "        \n",
    "    term_1 = (s2.q / s2.n)\n",
    "    term_2 = c_param * np.sqrt((2 * np.log(s1.n) / s2.n))\n",
    "    return  term_1 + term_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rollouts = 100\n",
    "max_steps = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_state = 5  # which state do we start?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory is a data structure (should it be restarted at each step?)\n",
    "m = {root_state: Node(root_state)}  # track states that we've seen before since we cant \"color\" environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rollout in range(n_rollouts):\n",
    "    s = root_state\n",
    "    trace = [s]\n",
    "    env.s = s  # manually set env to the state we want\n",
    "    done = False\n",
    "    steps = 0\n",
    "    \n",
    "    # the first action from root is determined differently from other actions, since it relies on ucb score\n",
    "    a = select_action_from_root(s, m, env)\n",
    "\n",
    "    while not done and steps < max_steps:\n",
    "        s, r, done, _ = env.step(a)\n",
    "        steps += 1\n",
    "\n",
    "        # if we've seen state s2 before, we dont need to do anything\n",
    "        if s in m:\n",
    "            pass\n",
    "        # if we havent seen state s2 before, we update memory and continue\n",
    "        else:\n",
    "            m[s] = Node(s)\n",
    "\n",
    "        # add action to trace so we can eventually backpropagate from terminal through root\n",
    "        trace.append(s)\n",
    "        \n",
    "        # select a new action\n",
    "        if not done:\n",
    "            a = select_action_from_root(s, m, env)\n",
    "\n",
    "    # now that we're done with the rollout... backpropagate the nodes in the trajectory\n",
    "    if r> 0:\n",
    "        print(\"rollout\", rollout, \"trace\", trace, \"with reward\", r)\n",
    "    \n",
    "    for t in set(trace):\n",
    "        node = m[t]  # retrieve node for corresponding state\n",
    "        node.q += r  # update reward\n",
    "        node.n += 1  # update games played\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = left; 1 = down; 2 = right;  3 = up\n",
    "best_a = select_action_from_root(root_state, m, env)\n",
    "s2, _, _, _ = env.step(best_a)\n",
    "print(\"from state\", root_state, \", our best move\", best_a, \"takes us to state\", s2)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
