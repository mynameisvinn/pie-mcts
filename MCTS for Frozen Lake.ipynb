{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym.envs.registration import register  # https://github.com/openai/gym/blob/master/gym/envs/registration.py\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "MY_ENV_NAME='FrozenLakeNonskid4x4-v0'\n",
    "\n",
    "# 0 = left; 1 = down; 2 = right;  3 = up\n",
    "# reward of 1 if success, no reward otherwise\n",
    "# done = True even if not success due to timestep limit\n",
    "\n",
    "register(\n",
    "    id=MY_ENV_NAME,\n",
    "    entry_point='gym.envs.toy_text:FrozenLakeEnv',\n",
    "    kwargs={'map_name': '8x8', 'is_slippery': False},\n",
    "    reward_threshold=0.78)\n",
    "\n",
    "env = gym.make(MY_ENV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    \"\"\"\n",
    "    each state will be represented as a State object. we do this \n",
    "    because we want to track (a) total rewards and (b) play count.\n",
    "    \n",
    "    we need to track rewards and play count in order to calculate\n",
    "    UCB score; we want to calculate UCB score in order to select \n",
    "    the most promising action.\n",
    "    \"\"\"\n",
    "    def __init__(self, state):\n",
    "        self.state = state\n",
    "        self.q = 0  # win count\n",
    "        self.n = 0  # play count\n",
    "\n",
    "\n",
    "def _find_valid_action_state_pairs(s1, env):\n",
    "    \"\"\"return a list of valid action/s2 pairs for a given s1.\n",
    "    \"\"\"\n",
    "    valid_actions = []\n",
    "    \n",
    "    # explore all four possible actions\n",
    "    for a in range(3):  \n",
    "        s2, _, _, _ = env.step(a)  # what would s2 look like if we took action a\n",
    "        \n",
    "        # scenario 1: action does not lead to a new state, so ignore\n",
    "        if s2 == s1:\n",
    "            pass\n",
    "        \n",
    "        # scenario 2: action leads to a new state so we will keep it\n",
    "        else:\n",
    "            valid_actions.append((a, s2))\n",
    "        \n",
    "        # return env to original state\n",
    "        env.s = s1  \n",
    "    return valid_actions\n",
    "        \n",
    "\n",
    "def _find_valid_actions(s, env):\n",
    "    \"\"\"return a list of valid actions for state s.\n",
    "    \"\"\"\n",
    "    valid_actions = []\n",
    "    \n",
    "    # explore all four possible actions\n",
    "    for a in range(3):  \n",
    "        s2, _, _, _ = env.step(a)  # what would s2 look like if we took action a\n",
    "        \n",
    "        # scenario 1: action does not lead to a new state, so ignore\n",
    "        if s2 == s:\n",
    "            pass\n",
    "        \n",
    "        # scenario 2: action leads to a new state so we will keep it\n",
    "        else:\n",
    "            valid_actions.append(a)\n",
    "        \n",
    "        # return env to original state\n",
    "        env.s = s\n",
    "    return valid_actions\n",
    "\n",
    "    \n",
    "def select_action_from_root(root, memory, env):\n",
    "    \"\"\"return an action from root. \n",
    "    \n",
    "    if root is unexpanded then return actions\n",
    "    that lead to unexplored states. if root is expanded (all possible s2 \n",
    "    from root s1 have been explored) then return action that leads to s2 \n",
    "    with highest UCB score.\n",
    "    \"\"\"\n",
    "    # step 1: find all actions that would lead to a valid state\n",
    "    action_states = _find_valid_action_state_pairs(root, env)\n",
    "    \n",
    "    # step 2a: if we havent seen that s2 before, then go with it\n",
    "    for ap in action_states:\n",
    "        a = ap[0]\n",
    "        s2 = ap[1]\n",
    "        if s2 in memory.keys():\n",
    "            pass\n",
    "        else:\n",
    "            return a  # this action leads to a state that we havent seen before\n",
    "        \n",
    "    # step 2b: if we've visited all possible s2 from root, return action that would lead to s2 with the highest UCB\n",
    "    action = action_states[0][0]\n",
    "    max_ucb = 0\n",
    "    for ap in action_states:\n",
    "        s1 = memory[root]\n",
    "        s2 = memory[ap[1]]\n",
    "        score = calculate_ucb(s1, s2)\n",
    "        if score > max_ucb:\n",
    "            action = ap[0]\n",
    "            max_ucb = score  # new score to beat\n",
    "    return action\n",
    "    \n",
    "def calculate_ucb(s1, s2):\n",
    "    \"\"\"compute ucb score between s1 and s2.\n",
    "    \"\"\"\n",
    "    c_param = .14\n",
    "    \n",
    "    # hack in case s2 is a pit\n",
    "    if s2.n == 0:\n",
    "        s2.n = 1\n",
    "        \n",
    "    term_1 = (s2.q / s2.n)\n",
    "    term_2 = c_param * np.sqrt((2 * np.log(s1.n) / s2.n))\n",
    "    return  term_1 + term_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rollouts = 100\n",
    "max_steps = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_state = 9  # which state do we start?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory is a data structure that persists through all rollouts\n",
    "m = {root_state: Node(root_state)}  # track states that we've seen before since we cant \"color\" environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rollout 0 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 1 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 2 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 3 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 4 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 5 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 6 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 7 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 8 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 9 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 10 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 11 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 12 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 13 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 14 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 15 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 16 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 17 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 18 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 19 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 20 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 21 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 22 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 23 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 24 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 25 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 26 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 27 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 28 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 29 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 30 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 31 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 32 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 33 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 34 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 35 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 36 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 37 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 38 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 39 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 40 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 41 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 42 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 43 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 44 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 45 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 46 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 47 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 48 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 49 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 50 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 51 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 52 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 53 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 54 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 55 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 56 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 57 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 58 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 59 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 60 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 61 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 62 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 63 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 64 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 65 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 66 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 67 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 68 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 69 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 70 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 71 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 72 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 73 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 74 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 75 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 76 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 77 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 78 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 79 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 80 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 81 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 82 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 83 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 84 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 85 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 86 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 87 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 88 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 89 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 90 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 91 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 92 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 93 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 94 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 95 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 96 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 97 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 98 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "rollout 99 trace [9, 10, 11, 12, 13, 14, 15, 23, 31, 39, 47, 55, 63] with reward 1.0\n",
      "-\n"
     ]
    }
   ],
   "source": [
    "for rollout in range(n_rollouts):\n",
    "    s = root_state\n",
    "    trace = [s]\n",
    "    env.s = s  # manually set env to the state we want\n",
    "    done = False\n",
    "    steps = 0\n",
    "    \n",
    "    # the first action has a unique sampling mechanism\n",
    "    # select actions based on UCB scores\n",
    "    a = select_action_from_root(s, m, env)\n",
    "\n",
    "    while not done and steps < max_steps:\n",
    "        s, r, done, _ = env.step(a)\n",
    "        steps += 1\n",
    "\n",
    "        # if we've seen state s before, we dont need to do anything\n",
    "        if s in m:\n",
    "            pass\n",
    "        # if we havent seen state s before, we update memory and continue\n",
    "        else:\n",
    "            m[s] = Node(s)\n",
    "\n",
    "        # add action to trace so we can eventually backpropagate from terminal through root\n",
    "        trace.append(s)\n",
    "        \n",
    "        # any action thereafter is random exploration\n",
    "        if not done:\n",
    "            a = select_action_from_root(s, m, env)\n",
    "\n",
    "    # now that we're done with the rollout... backpropagate the nodes in the trajectory\n",
    "    if r> 0:\n",
    "        print(\"rollout\", rollout, \"trace\", trace, \"with reward\", r)\n",
    "    \n",
    "    for t in set(trace):\n",
    "        node = m[t]  # retrieve node for corresponding state\n",
    "        node.q += r  # update reward\n",
    "        node.n += 1  # update games played\n",
    "print(\"-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from state 8 , our best move 2 takes us to state 9\n",
      "  (Right)\n",
      "SFFFFFFF\n",
      "F\u001b[41mF\u001b[0mFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFFHFHF\n",
      "FFFHFFFG\n"
     ]
    }
   ],
   "source": [
    "# 0 = left; 1 = down; 2 = right;  3 = up\n",
    "best = select_action_from_root(root_state, m, env)\n",
    "s2, _, _, _ = env.step(best)\n",
    "print(\"from state\", root_state, \", our best move\", best, \"takes us to state\", s2)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (Right)\n",
      "SFFFFFFF\n",
      "FFFFFFFF\n",
      "FFFHFFFF\n",
      "FFFFFHFF\n",
      "FFFHFFFF\n",
      "FHHFFFHF\n",
      "FHFF\u001b[41mH\u001b[0mFHF\n",
      "FFFHFFFG\n"
     ]
    }
   ],
   "source": [
    "env.s = 52\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
